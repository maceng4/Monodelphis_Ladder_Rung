{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy \n",
    "from scipy.signal import chirp, find_peaks, peak_widths\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics \n",
    "from scipy.spatial.distance import cdist \n",
    "\n",
    "\n",
    "#import warnings #check your version of scipy/numpy/matplolib if you receive warnings (wont affect data)\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load all datasets in \n",
    "\n",
    "subject_1_trail_1 = pd.read_csv('Name_of_File.csv')\n",
    "subject_1_trail_2 = pd.read_csv('Name_of_File.csv')\n",
    "\n",
    "subject1 = pd.concat([subject_1_trail_1, subject_1_trail_2])\n",
    "\n",
    "\n",
    "\n",
    "subject_2_trail_1 = pd.read_csv('Name_of_File.csv')\n",
    "subject_2_trail_2 = pd.read_csv('Name_of_File.csv')\n",
    "\n",
    "subject2 = pd.concat([subject_2_trail_1, subject_2_trail_2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_scaling(one_possum,scale):\n",
    "    one_possum['RFLy_disp_scale'] = one_possum['RFLy_disp'] / scale\n",
    "    one_possum['RHL_disp_scale'] =  one_possum['RHLy_disp'] / scale\n",
    "    one_possum['Snouty_disp_scale'] = one_possum['Snouty_disp'] / scale\n",
    "    one_possum['Tailtipy_disp_scale'] =  one_possum['Tailtipy_disp'] / scale\n",
    "    \n",
    "    one_possum['RFLx_cumsum_scale'] =  one_possum['RFLx_cumsum'] / scale\n",
    "    one_possum['RHLx_cumsum_scale'] =  one_possum['RHLx_cumsum'] / scale\n",
    "    \n",
    "    one_possum['RFLx_scale'] =  one_possum['RFLx'] / scale\n",
    "    one_possum['RHLx_scale'] =  one_possum['RHLx'] / scale\n",
    "    one_possum['Snoutx_scale'] =  one_possum['Snoutx'] / scale\n",
    "    \n",
    "add_scaling(subject1,1.0) # replace 1.0 with your own scale\n",
    "add_scaling(subject2,1.0) # replace 1.0 with your own scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place your dataset names in the brackets to combine datasets based on condition\n",
    "agg_male = pd.concat([]) \n",
    "agg_female = pd.concat([])\n",
    "\n",
    "\n",
    "# use search functions to locate correct placements or misses, and create datasets on just those factors. \n",
    "# various examples of this sare shown here\n",
    "agg_male_correct = agg_male.loc[agg_male['Strike_Type']=='Correct']\n",
    "agg_female_correct = agg_female.loc[agg_female['Strike_Type']=='Correct']\n",
    "\n",
    "agg_male_miss = agg_male.loc[agg_male['Strike_Type']=='Miss']\n",
    "agg_female_miss = agg_female.loc[agg_female['Strike_Type']=='Miss']\n",
    "\n",
    "agg_data = pd.concat([agg_male_correct,agg_female_correct])\n",
    "agg_miss = pd.concat([agg_male_miss,agg_female_miss])\n",
    "\n",
    "\n",
    "# to combine all data, start by listing your data-frames here \n",
    "agg_correct_and_miss_list = pd.concat([]\n",
    "\n",
    "\n",
    "# or you can combine just some data. list in brackets separated by commas.\n",
    "agg_data = pd.concat([])\n",
    "\n",
    "                                      \n",
    "# This section adds various parameters for analysis, such as the distance between the left hindlimb (LHLx) \n",
    "# and snout (Snoutx) during a limb motion\n",
    "agg_data['LHL_vs_Snout'] = agg_data['Snoutx'] - agg_data['LHLx']\n",
    "agg_data['RHL_vs_Snout'] = agg_data['Snoutx'] - agg_data['RHLx']\n",
    "agg_data['RFL_vs_Snout'] = agg_data['Snoutx'] - agg_data['RFLx']\n",
    "agg_data['LFL_vs_Snout'] = agg_data['Snoutx'] - agg_data['LFLx']\n",
    "agg_data['RFL_vs_LHL'] = agg_data['RFLx'] - agg_data['LHLx']\n",
    "agg_data['RFL_vs_RHL'] = agg_data['RFLx'] - agg_data['RHLx']\n",
    "\n",
    "agg_data['RFL_vs_RHL_scale'] = agg_data['RFLx_scale'] - agg_data['RHLx_scale']\n",
    "agg_data['RHL_vs_Snout_scale'] = agg_data['Snoutx_scale'] - agg_data['RHLx_scale']\n",
    "\n",
    "agg_data['RFL_vs_RHL'] = agg_data['RFLx'] - agg_data['RHLx']\n",
    "agg_data['snout_vs_tail'] = agg_data['Snouty_disp'] - agg_data['Tailtipy_disp']\n",
    "\n",
    "agg_data['RFL_vs_Snout_scale'] = agg_data['Snoutx_scale'] - agg_data['RFLx_scale']\n",
    "\n",
    "\n",
    "# Now you'll need to re-index. If each strike is not 100 frames long, you will need to adjust the i/100 value\n",
    "# by changing the denominator to the appropriate strike length. \n",
    "\n",
    "from math import floor\n",
    "val = 0 \n",
    "agg_data['strike_tot'] = [val + floor(i / 100) for i in range(len(agg_data.index))] \n",
    "#listit = list(range(100))\n",
    "\n",
    "agg_misses_whisker['strike_tot'] = [val + floor(i / 100) for i in range(len(agg_misses_whisker.index))] \n",
    "\n",
    "\n",
    "print ('Length of total correct strikes is:',len(agg_data))\n",
    "print ('Length of total missed strikes is:',len(agg_miss))\n",
    "print ('Length of total EB strikes is:',len(eb_only_correct))\n",
    "print ('Length of total SC strikes is:',len(sc_only_correct))\n",
    "print ('Length of total with whisker strikes is:',len(whiskers_only))\n",
    "print ('Length of total whisker trimmed strikes is:',len(whisker_trim_only))\n",
    "print ('Length of total misses is:',len(agg_misses_whisker))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alter the parameters in this box to get a combined linepot comparing two conditions\n",
    "# you will need to make sure condition is a column in your data-set. \n",
    "plt.rcParams['figure.figsize']=(20,7)\n",
    "my_pal= {'Condition1':'mediumblue','Condition2':'crimson'}\n",
    "sns.lineplot(x=\"x_vals\", y=\"RFLy_disp\",hue = 'condition',data= agg_data)\n",
    "plt.xlabel('Frame', fontsize=20)\n",
    "plt.ylabel('RFLy_disp', fontsize=20)\n",
    "plt.tick_params(axis = 'both', which = 'major', labelsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whiskers do change the X-component of motion in EB animals, with shorter steps \n",
    "my_pal= {'Condition3':'mediumblue','Condition4':'dodgerblue'}\n",
    "plt.rcParams['figure.figsize']=(20,7)\n",
    "af = sns.lineplot(x=\"x_vals\", y=\"RFLx_cumsum_scale\",hue = 'Experimental_Condition',\n",
    "             style = 'Experimental_Condition',linewidth=2,data=YOUR DATA, \n",
    "             palette = my_pal,legend= False) #make sure to put the name of your dataframe here\n",
    "\n",
    "af.set_ylim(-1,10)\n",
    "plt.xlabel('Frame', fontsize=20)\n",
    "plt.ylabel('RFLx_disp', fontsize=20)\n",
    "plt.tick_params(axis = 'both', which = 'major', labelsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the trajectory of misses is similar across conditions, try making a combined 'miss' file so you can display it here\n",
    "plt.rcParams['figure.figsize']=(20,7)\n",
    "my_pal= {'Condition1':'mediumblue','Condition2':'crimson'}\n",
    "dlc_miss = sns.lineplot(x=\"x_vals\", y=\"RFLy_disp\",hue = 'condition',\n",
    "                        linewidth = 2, data=agg_miss,palette = my_pal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can also try a violin plot\n",
    "plt.rcParams['figure.figsize']=(10,7)\n",
    "my_pal= {'Condition1':'mediumblue','Condition2':'crimson','Condition3':'gray','Condition4':'lightgray'}\n",
    "sns.violinplot(x='condition',y='Snouty_disp_scale',hue='Experimental_Condition',style='Experimental_Condition',\n",
    "             linewidth =2,data=agg_data,palette=my_pal)\n",
    "\n",
    "#Example of stats you can run:\n",
    "#model = smf.ols(formula = 'Snouty_disp_scale ~ condition', data = agg_data)\n",
    "#result_of_anova = model.fit()\n",
    "#print(result_of_anova.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or you can test out graphing the distance between the right forelimb (RFL) and right hindlimb (RHL) during a motion\n",
    "my_pal= {'Condition1':'mediumblue','Condition2':'dodgerblue'}\n",
    "plt.rcParams['figure.figsize']=(15,7)\n",
    "a= sns.lineplot(x=\"x_vals\", y=\"RFL_vs_RHL_scale\",hue = 'condition',style='condition',\n",
    "             linewidth =2,data=YOUR_DATA, palette = my_pal,legend=False) #dont forget to put your own data here.\n",
    "a.set_ylim(0,8)\n",
    "\n",
    "#a.figure.savefig('RFL_RHL_lineplot.pdf') # you can also save the figure as a pdf or png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snout to forelimb comparison \n",
    "my_pal= {'condition1':'mediumblue','condition2':'crimson'}\n",
    "plt.rcParams['figure.figsize']=(20,7)\n",
    "sns.lineplot(x=\"x_vals\", y=\"RFL_vs_Snout\",hue = 'condition',\n",
    "             linewidth =2,data=agg_data,palette = my_pal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agg_data2 = pd.concat([your_data1,your_data2,your_data3])\n",
    "# or use pre-existing data\n",
    "agg_data2 = pd.concat([subject1,subject2])\n",
    "\n",
    "# Then need to rename the strikes so it gives us strikes 1 thru X\n",
    "# 100 is the width of each strike \n",
    "#from math import floor #should already be imported\n",
    "val = 0 \n",
    "agg_data2['strike'] = [val + floor(i / 100) for i in range(len(agg_data2.index))] \n",
    "listit = list(range(100))\n",
    "\n",
    "\n",
    "#SELECTS JUST Forelimb Data, but this could be any body part\n",
    "cluster_data = agg_data2[['x_vals','strike','RFLy_disp_scale']]\n",
    "cluster_pivot = cluster_data.pivot(index='x_vals',columns='strike',values ='RFLy_disp_scale')\n",
    "cluster_pivot_array = cluster_pivot.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run the PCA\n",
    "\n",
    "mean_pivot = np.mean(cluster_pivot_array)\n",
    "cluster_pivot_scaled = cluster_pivot_array - mean_pivot\n",
    "cluster_try = cluster_pivot.T #transforms the dataframe\n",
    "cluster_try_array = cluster_try.values\n",
    "\n",
    "\n",
    "# Apply standard scaling or pick a different scaler\n",
    "#scaler= sk.preprocessing.MinMaxScaler()\n",
    "scaler =sk.preprocessing.StandardScaler()\n",
    "#scaler = sk.preprocessing.RobustScaler()\n",
    "#scaler = sk.preprocessing.Normalizer()\n",
    "dataset_scaled = scaler.fit_transform(cluster_try_array)\n",
    "\n",
    "\n",
    "# choose number of components\n",
    "pca=PCA(n_components=4)\n",
    "pca_result = pca.fit_transform(dataset_scaled)\n",
    "#print(pca.explained_variance_)\n",
    "\n",
    "\n",
    "#Use K-Means for visualization \n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(pca_result)\n",
    "y_kmeans = kmeans.predict(pca_result)\n",
    "plt.scatter(pca_result[:, 0], pca_result[:, 1], c=y_kmeans, s=50)\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from https://www.geeksforgeeks.org/elbow-method-for-optimal-value-of-k-in-kmeans/\n",
    "\n",
    "# Elbow point method \n",
    "distortions = [] \n",
    "inertias = [] \n",
    "mapping1 = {} \n",
    "mapping2 = {} \n",
    "K = range(1,10) \n",
    "  \n",
    "for k in K: \n",
    "    #Building and fitting the model \n",
    "    kmeanModel = KMeans(n_clusters=k).fit(cluster_try_array) \n",
    "    kmeanModel.fit(cluster_try_array)     \n",
    "      \n",
    "    distortions.append(sum(np.min(cdist(cluster_try_array, kmeanModel.cluster_centers_, \n",
    "                      'euclidean'),axis=1)) / cluster_try_array.shape[0]) \n",
    "    inertias.append(kmeanModel.inertia_) \n",
    "  \n",
    "    mapping1[k] = sum(np.min(cdist(cluster_try_array, kmeanModel.cluster_centers_, \n",
    "                 'euclidean'),axis=1)) / cluster_try_array.shape[0] \n",
    "    mapping2[k] = kmeanModel.inertia_\n",
    "    \n",
    "\n",
    "for key,val in mapping1.items(): \n",
    "    print(str(key)+' : '+str(val))\n",
    "    \n",
    "    \n",
    "plt.plot(K, distortions, 'bx-') \n",
    "plt.xlabel('Values of K') \n",
    "plt.ylabel('Distortion') \n",
    "plt.title('The Elbow Method using Distortion') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Silhouette Coefficient\n",
    "\n",
    "import csv \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "range_n_clusters = [1,2,3,4,5,6,7,8] #or any number of clusters here\n",
    "\n",
    "for i in range_n_clusters:\n",
    "    clusterer = KMeans(n_clusters=i,random_state = 10)\n",
    "    cluster_labels = clusterer.fit_predict(cluster_try_array)\n",
    "    silhouette_avg = silhouette_score(cluster_try_array, cluster_labels)\n",
    "    print('For',i,'clusters',\n",
    "         'average silhouette score is:',silhouette_avg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run clustering, add labels, and plot\n",
    "\n",
    "kk = KMeans(n_clusters=4)\n",
    "kk.fit(cluster_try_array)\n",
    "y_kk= kk.predict(cluster_try_array)\n",
    "\n",
    "result= kk.labels_\n",
    "cluster_try['label']=result\n",
    "\n",
    "\n",
    "cluster_long = pd.melt(cluster_try,id_vars=[('label')],var_name='x_vals',value_name='disp')\n",
    "cluster_rest = cluster_try.copy()\n",
    "cluster_rest['new_strike'] = cluster_rest.index\n",
    "\n",
    "cluster_long1 = pd.melt(cluster_rest,id_vars=['new_strike','label'],\n",
    "                        var_name='x_vals',value_name='disp')\n",
    "\n",
    "import seaborn as sns\n",
    "my_pal = {0:'mediumblue',1:'mediumblue',2:'mediumblue',3:'mediumblue'}\n",
    "plt.rcParams['figure.figsize']=(15,7)\n",
    "km=sns.lineplot(x=\"x_vals\", y=\"disp\",hue = 'label',linewidth=2,data=cluster_long,\n",
    "                palette=my_pal,legend=False)\n",
    "\n",
    "#km.set_ylim(-.2,1.3) # enter these values \n",
    "#km.figure.savefig('Your_file.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and then you can save any data as a csv here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
